# HorizonOS AI Integration

Welcome to the HorizonOS AI Integration system! This directory contains the implementation of our privacy-first, local AI system that brings intelligent automation and assistance to HorizonOS.

## ğŸš€ Quick Start

### For Users

1. **Enable AI Features**
   ```bash
   sudo systemctl enable --now horizonos-ai.target
   ```

2. **Check Status**
   ```bash
   horizonos-ai status
   ```

3. **Configure Settings**
   Edit `/etc/horizonos/ai/settings.horizonos.kts` or use the Settings app

### For Developers

1. **Setup Development Environment**
   ```bash
   ./scripts/setup-ai-dev.sh
   ```

2. **Run Tests**
   ```bash
   cd src/desktop/graph-ai && cargo test
   ```

3. **Access Services**
   - Ollama API: http://localhost:11434
   - n8n Workflows: http://localhost:5678
   - Grafana Metrics: http://localhost:3000

## ğŸ“ Project Structure

```
horizonos/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AI Integration Design Document.md    # Original design specification
â”‚   â”œâ”€â”€ AI_INTEGRATION_IMPLEMENTATION_PLAN.md # Development roadmap
â”‚   â”œâ”€â”€ AI_INTEGRATION_USER_GUIDE.md         # End-user documentation
â”‚   â”œâ”€â”€ AI_INTEGRATION_TECHNICAL_GUIDE.md    # Developer documentation
â”‚   â””â”€â”€ AI_INTEGRATION_API_REFERENCE.md      # API documentation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ desktop/graph-ai/                    # Core AI implementation (Rust)
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ agents/                      # AI agent framework
â”‚   â”‚   â”‚   â”œâ”€â”€ automation/                  # RPA and automation
â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring/                  # Event monitoring
â”‚   â”‚   â”‚   â”œâ”€â”€ patterns/                    # Pattern detection
â”‚   â”‚   â”‚   â”œâ”€â”€ privacy/                     # Privacy controls
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/                     # Data persistence
â”‚   â”‚   â”‚   â”œâ”€â”€ suggestions/                 # Suggestion engine
â”‚   â”‚   â”‚   â”œâ”€â”€ hardware.rs                  # Hardware detection
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama.rs                    # LLM integration
â”‚   â”‚   â”‚   â””â”€â”€ lib.rs                       # Main library
â”‚   â”‚   â””â”€â”€ Cargo.toml
â”‚   â”‚
â”‚   â””â”€â”€ kotlin-config/                       # Configuration DSL
â”‚       â””â”€â”€ src/main/kotlin/org/horizonos/
â”‚           â””â”€â”€ config/dsl/ai/               # AI settings DSL
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-ai-dev.sh                      # Development setup
â”‚   â”œâ”€â”€ deploy-ai-system.sh                  # Production deployment
â”‚   â”œâ”€â”€ sql/
â”‚   â”‚   â””â”€â”€ init-timescaledb.sql             # Database schema
â”‚   â””â”€â”€ systemd/                             # Service definitions
â”‚       â”œâ”€â”€ horizonos-ai.service
â”‚       â”œâ”€â”€ horizonos-ai-monitor.service
â”‚       â”œâ”€â”€ horizonos-ai-agents.service
â”‚       â””â”€â”€ horizonos-ai.target
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/                         # Integration tests
â”‚   â””â”€â”€ benchmarks/                          # Performance tests
â”‚
â””â”€â”€ docker-compose.yml                       # Container orchestration
```

## ğŸ¯ Key Features

### 1. **Privacy-First Design**
- All AI processing happens locally
- No data leaves your machine
- Full control over what's monitored
- Encrypted storage with user-controlled keys

### 2. **Intelligent Automation**
- Learn from your workflows
- Suggest optimizations
- Automate repetitive tasks
- Visual workflow builder (n8n)

### 3. **Hardware Optimization**
- Automatic GPU detection
- Adaptive model selection
- Resource-aware processing
- Battery-conscious operation

### 4. **Multi-Agent System**
- Specialized AI assistants
- Task decomposition
- Parallel processing
- Context-aware responses

## ğŸ› ï¸ Technical Stack

- **Language Models**: Ollama (local LLM runtime)
- **AI Framework**: LangChain for agent orchestration
- **Time-Series DB**: TimescaleDB for behavioral data
- **Automation**: n8n workflows, Playwright, ydotool
- **Languages**: Rust (core), Kotlin (config DSL)
- **Container**: Docker Compose for services

## ğŸ“Š Architecture Overview

```
User Input â†’ Privacy Filter â†’ Event Monitor â†’ Pattern Detection
                                    â†“
                            TimescaleDB Storage
                                    â†“
                        AI Analysis (Ollama/LangChain)
                                    â†“
                        Suggestion/Automation Engine
                                    â†“
                            User Action/Notification
```

## ğŸ”§ Configuration

The AI system uses Kotlin DSL for type-safe configuration:

```kotlin
aiSettings {
    enabled = true
    
    hardware {
        optimization = HardwareOptimization.AUTO
        preferGPU = true
    }
    
    privacy {
        localOnly = true
        encryptStorage = true
        dataRetention = 30.days
    }
    
    learning {
        enabled = true
        excludeApplications = listOf("keepassxc", "signal-desktop")
    }
}
```

## ğŸ“¡ API Access

### REST API
```bash
# Generate completion
curl -X POST http://localhost:8090/api/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hello", "model": "llama3.2"}'

# Get suggestions  
curl http://localhost:8090/api/suggestions/current
```

### D-Bus Integration
```python
import dbus
bus = dbus.SessionBus()
ai = bus.get_object('org.horizonos.AI', '/org/horizonos/AI')
suggestions = ai.GetSuggestions("current")
```

## ğŸ§ª Testing

```bash
# Unit tests
cargo test

# Integration tests
cargo test --features integration-tests

# Performance benchmarks
cargo bench

# Run specific test
cargo test test_ollama_client
```

## ğŸš€ Deployment

### Development
```bash
./scripts/setup-ai-dev.sh
```

### Production
```bash
sudo ./scripts/deploy-ai-system.sh --production
```

## ğŸ“ˆ Performance

- **Memory**: ~100MB for monitoring service
- **CPU**: <5% during normal operation
- **Response Time**: <500ms for suggestions
- **Model Loading**: 2-10s depending on size

## ğŸ”’ Security

- Local-only processing by default
- Encrypted storage (AES-256-GCM)
- Sandboxed automation execution
- Granular permission system
- Complete audit logging

## ğŸ¤ Contributing

1. Read the [Design Document](docs/AI%20Integration%20Design%20Document.md)
2. Check the [Implementation Plan](docs/AI_INTEGRATION_IMPLEMENTATION_PLAN.md)
3. Follow the [Technical Guide](docs/AI_INTEGRATION_TECHNICAL_GUIDE.md)
4. Submit PRs with tests and documentation

## ğŸ“š Documentation

- **Users**: [AI Integration User Guide](docs/AI_INTEGRATION_USER_GUIDE.md)
- **Developers**: [AI Integration Technical Guide](docs/AI_INTEGRATION_TECHNICAL_GUIDE.md)
- **API**: [AI Integration API Reference](docs/AI_INTEGRATION_API_REFERENCE.md)

## ğŸ› Troubleshooting

```bash
# Check service status
systemctl status horizonos-ai.target

# View logs
journalctl -u horizonos-ai.service -f

# Run diagnostics
horizonos-ai diagnose --verbose

# Get help
horizonos-ai help
```

## ğŸ“œ License

This project is part of HorizonOS and follows the same license terms.

---

Built with â¤ï¸ for privacy, powered by local AI ğŸ¤–